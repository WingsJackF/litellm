"""
æ¨¡å‹ç®¡ç†å™¨æµ‹è¯•æ–‡ä»¶
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ ModelManager è¿›è¡Œæ¨¡å‹è°ƒç”¨
"""

from model_manager import model_manager
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage


def list_available_models():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
    print("=" * 60)
    print("ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨")
    print("=" * 60)
    
    # 1. æ˜¾ç¤ºå·²çŸ¥æ¨¡å‹
    print("\nğŸ”¹ å·²çŸ¥æ¨¡å‹ (Known Models):")
    for model_name, provider in model_manager.known_models.items():
        config = model_manager.get_model_config(model_name)
        supports = []
        if config:
            if config.supports_vision:
                supports.append("è§†è§‰")
            if config.supports_functions:
                supports.append("å‡½æ•°")
            if config.supports_streaming:
                supports.append("æµå¼")
        support_str = f" [{', '.join(supports)}]" if supports else ""
        print(f"  â€¢ {model_name:30s} (æä¾›å•†: {provider}){support_str}")
    
    # 2. æ˜¾ç¤ºè‡ªå®šä¹‰æ¨¡å‹
    custom_models = [name for name in model_manager.models.keys() 
                     if name not in model_manager.known_models]
    if custom_models:
        print("\nğŸ”¹ è‡ªå®šä¹‰æ¨¡å‹ (Custom Models):")
        for model_name in custom_models:
            config = model_manager.get_model_config(model_name)
            print(f"  â€¢ {model_name:30s} (æä¾›å•†: {config.provider})")
    
    # 3. æ˜¾ç¤ºæ¨¡å‹åˆ«å
    if model_manager.model_aliases:
        print("\nğŸ”¹ æ¨¡å‹åˆ«å (Model Aliases):")
        for alias, real_name in model_manager.model_aliases.items():
            print(f"  â€¢ {alias} â†’ {real_name}")
    
    # 4. æ˜¾ç¤ºæ”¯æŒçš„æä¾›å•†
    print("\nğŸ”¹ æ”¯æŒçš„æä¾›å•† (Providers):")
    for provider in model_manager.providers:
        api_base = model_manager.provider_api_bases.get(provider, "N/A")
        print(f"  â€¢ {provider:15s} - {api_base}")
    
    print("\n" + "=" * 60)
    print(f"âœ… æ€»è®¡: {len(model_manager.models)} ä¸ªæ¨¡å‹\n")


def test_simple_chat():
    """æµ‹è¯•ç”¨ä¾‹ 1: ç®€å•å¯¹è¯"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•ç”¨ä¾‹ 1: ç®€å•å¯¹è¯")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ¶ˆæ¯ (ä½¿ç”¨ LangChain Message å¯¹è±¡)
        messages = [
            HumanMessage(content="ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚")
        ]
        
        # è°ƒç”¨æ¨¡å‹
        model_name = "gpt-4o"  # å¯ä»¥ä¿®æ”¹ä¸ºå…¶ä»–æ¨¡å‹
        print(f"\nğŸ“¤ æ­£åœ¨è°ƒç”¨æ¨¡å‹: {model_name}")
        print(f"ğŸ’¬ æ¶ˆæ¯: {messages[0].content}")
        
        response = model_manager.chat(
            model=model_name,
            messages=messages
        )
        print(response)
        print(f"\nğŸ“¥ å“åº”:")
        print(f"  ç±»å‹: {type(response).__name__}")
        print(f"  å†…å®¹: {response.content}")
        
        # è·å– token ä½¿ç”¨æƒ…å†µ
        client = model_manager.get_model(model_name)
        if hasattr(client, 'callbacks') and client.callbacks:
            for callback in client.callbacks:
                if hasattr(callback, 'input_tokens'):
                    print(f"\nğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡:")
                    print(f"  è¾“å…¥ tokens: {callback.input_tokens}")
                    print(f"  è¾“å‡º tokens: {callback.output_tokens}")
                    print(f"  æ€»è®¡ tokens: {callback.total_tokens}")
                    print(f"  è€—æ—¶: {callback.total_duration:.2f}ç§’")
        
        print("\nâœ… æµ‹è¯•é€šè¿‡!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def test_multi_turn_chat():
    """æµ‹è¯•ç”¨ä¾‹ 2: å¤šè½®å¯¹è¯"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•ç”¨ä¾‹ 2: å¤šè½®å¯¹è¯")
    print("=" * 60)
    
    try:
        # åˆ›å»ºå¤šè½®å¯¹è¯æ¶ˆæ¯
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚"),
            HumanMessage(content="Python ä¸­å¦‚ä½•å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Ÿ"),
            AIMessage(content="åœ¨ Python ä¸­ï¼Œä½¿ç”¨ `def` å…³é”®å­—å®šä¹‰å‡½æ•°ã€‚"),
            HumanMessage(content="èƒ½ç»™ä¸€ä¸ªä¾‹å­å—ï¼Ÿ")
        ]
        
        model_name = "gpt-4o"
        print(f"\nğŸ“¤ æ­£åœ¨è°ƒç”¨æ¨¡å‹: {model_name}")
        print(f"ğŸ’¬ å¯¹è¯è½®æ•°: {len(messages)} æ¡æ¶ˆæ¯")
        
        response = model_manager.chat(
            model=model_name,
            messages=messages
        )
        print(response)
        print(f"\nğŸ“¥ å“åº”:")
        print(f"  {response}")
        
        print("\nâœ… æµ‹è¯•é€šè¿‡!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def test_streaming_chat():
    """æµ‹è¯•ç”¨ä¾‹ 3: æµå¼è¾“å‡º"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•ç”¨ä¾‹ 3: æµå¼è¾“å‡º")
    print("=" * 60)
    
    try:
        messages = [
            HumanMessage(content="ç”¨ä¸‰å¥è¯è®²ä¸€ä¸ªå°æ•…äº‹ã€‚")
        ]
        
        model_name = "gpt-4o"
        print(f"\nğŸ“¤ æ­£åœ¨è°ƒç”¨æ¨¡å‹: {model_name} (æµå¼)")
        print(f"ğŸ’¬ æ¶ˆæ¯: {messages[0].content}")
        print(f"\nğŸ“¥ æµå¼å“åº”:")
        print("-" * 60)
        
        stream = model_manager.chat(
            model=model_name,
            messages=messages,
            stream=True
        )
        
        full_response = ""
        for chunk in stream:
            content = chunk.content
            print(content, end="", flush=True)
            full_response += content
        
        print("\n" + "-" * 60)
        print(f"âœ… æ¥æ”¶å®Œæˆï¼Œæ€»é•¿åº¦: {len(full_response)} å­—ç¬¦")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def test_with_tools():
    """æµ‹è¯•ç”¨ä¾‹ 4: ä½¿ç”¨å·¥å…· (Tool Calling)"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•ç”¨ä¾‹ 4: å·¥å…·è°ƒç”¨")
    print("=" * 60)
    
    try:
        # å®šä¹‰å·¥å…·
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "city": {
                                "type": "string",
                                "description": "åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·"
                            }
                        },
                        "required": ["city"]
                    }
                }
            }
        ]
        
        messages = [
            HumanMessage(content="åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
        ]
        
        model_name = "gpt-4o"
        print(f"\nğŸ“¤ æ­£åœ¨è°ƒç”¨æ¨¡å‹: {model_name}")
        print(f"ğŸ’¬ æ¶ˆæ¯: {messages[0].content}")
        print(f"ğŸ”§ å·¥å…·æ•°é‡: {len(tools)}")
        
        response = model_manager.chat(
            model=model_name,
            messages=messages,
            tools=tools
        )
        print(response)
        print(f"\nğŸ“¥ å“åº”:")
        print(f"  å†…å®¹: {response}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if hasattr(response, 'tool_calls') and response.tool_calls:
            print(f"  ğŸ”§ å·¥å…·è°ƒç”¨:")
            for tool_call in response.tool_calls:
                print(f"    â€¢ å‡½æ•°: {tool_call.get('name', 'N/A')}")
                print(f"    â€¢ å‚æ•°: {tool_call.get('args', {})}")
        
        print("\nâœ… æµ‹è¯•é€šè¿‡!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def test_register_custom_model():
    """æµ‹è¯•ç”¨ä¾‹ 5: æ³¨å†Œè‡ªå®šä¹‰æ¨¡å‹"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•ç”¨ä¾‹ 5: æ³¨å†Œè‡ªå®šä¹‰æ¨¡å‹")
    print("=" * 60)
    
    try:
        # æ³¨å†Œä¸€ä¸ªè‡ªå®šä¹‰æ¨¡å‹
        custom_model_name = "my-custom-model"
        config = model_manager.register_model(
            model_name=custom_model_name,
            provider="openai",
            api_base="https://api.custom.com/v1",
            api_key="sk-custom-key-xxx",
            supports_streaming=True,
            supports_functions=True,
            max_tokens=4096
        )
        
        print(f"\nâœ… æˆåŠŸæ³¨å†Œè‡ªå®šä¹‰æ¨¡å‹:")
        print(f"  æ¨¡å‹åç§°: {config.model_name}")
        print(f"  æä¾›å•†: {config.provider}")
        print(f"  API Base: {config.api_base}")
        print(f"  æœ€å¤§ tokens: {config.max_tokens}")
        
        # éªŒè¯æ˜¯å¦å¯ä»¥è·å–é…ç½®
        retrieved_config = model_manager.get_model_config(custom_model_name)
        if retrieved_config:
            print(f"\nâœ… æ¨¡å‹é…ç½®å·²æŒä¹…åŒ–åˆ° model.json")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "ğŸš€" * 30)
    print("ModelManager å®Œæ•´æµ‹è¯•å¥—ä»¶")
    print("ğŸš€" * 30 + "\n")
    
    # åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹
    list_available_models()
    
    # è¿è¡Œæµ‹è¯•ç”¨ä¾‹
    # æ³¨æ„: éœ€è¦é…ç½®ç›¸åº”çš„ API Key æ‰èƒ½è¿è¡Œ
    print("\nâš ï¸  æç¤º: ä»¥ä¸‹æµ‹è¯•éœ€è¦é…ç½® API Key (åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® API_KEY æˆ– OPENAI_API_KEY)")
    print("å¦‚æœæ²¡æœ‰é…ç½®ï¼Œæµ‹è¯•å°†å¤±è´¥ã€‚\n")
    
    user_input = input("æ˜¯å¦è¿è¡Œæµ‹è¯•ç”¨ä¾‹ï¼Ÿ(y/n): ")
    if user_input.lower() == 'y':
        test_simple_chat()
        test_multi_turn_chat()
        test_streaming_chat()
        test_with_tools()
        test_register_custom_model()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    main()

