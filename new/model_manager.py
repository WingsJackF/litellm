"""
ç®€åŒ–ç‰ˆæ¨¡å‹ç®¡ç†å™¨
åŸºäº LiteLLM çš„è®¾è®¡æ€è·¯ï¼Œå®ç°æ¨¡å‹çš„æ³¨å†Œã€è¯†åˆ«å’Œç®¡ç†åŠŸèƒ½
"""

import os
import json
from pathlib import Path
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass, field, asdict
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()


@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®ç±»"""
    model_name: str
    provider: str
    api_base: Optional[str] = None
    api_key: Optional[str] = None
    default_params: Dict = field(default_factory=dict)
    supports_streaming: bool = True
    supports_functions: bool = False
    supports_vision: bool = False
    max_tokens: Optional[int] = None


class ModelManager:
    """
    æ¨¡å‹ç®¡ç†å™¨ - ç®¡ç†å’Œè¯†åˆ«ä¸åŒçš„ LLM æ¨¡å‹
    
    åŠŸèƒ½ï¼š
    1. æ³¨å†Œå’Œç®¡ç†æ¨¡å‹é…ç½®
    2. æ ¹æ®æ¨¡å‹åç§°è‡ªåŠ¨è¯†åˆ«æä¾›å•†
    3. è·å–æ¨¡å‹çš„ API é…ç½®ä¿¡æ¯
    4. æ”¯æŒæ¨¡å‹åˆ«åæ˜ å°„
    """
    
    def __init__(self, model_file: str = "model.json"):
        """
        åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        
        Args:
            model_file: æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º model.json
        """
        # æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
        self.model_file = Path(__file__).parent / model_file
        
        # å·²æ³¨å†Œçš„æ¨¡å‹é…ç½®
        self.models: Dict[str, ModelConfig] = {}
        
        # æä¾›å•†åˆ—è¡¨
        self.providers: List[str] = [
            "openai", "anthropic", "azure", "cohere", "replicate",
            "huggingface", "groq", "mistral", "deepseek", "together_ai",
            "perplexity", "anyscale", "bedrock", "vertex_ai", "google", "ollama"
        ]
        
        # æä¾›å•†é»˜è®¤ API Base URL æ˜ å°„
        self.provider_api_bases: Dict[str, str] = {
            "openai": "https://api.openai.com/v1",
            "anthropic": "https://api.anthropic.com",
            "google": "https://generativelanguage.googleapis.com/v1",
            "groq": "https://api.groq.com/openai/v1",
            "mistral": "https://api.mistral.ai/v1",
            "deepseek": "https://api.deepseek.com/v1",
            "together_ai": "https://api.together.xyz/v1",
            "perplexity": "https://api.perplexity.ai",
            "anyscale": "https://api.endpoints.anyscale.com/v1",
            "ollama": "http://localhost:11434/v1",
        }
        
        # å·²çŸ¥æ¨¡å‹åˆ°æä¾›å•†çš„æ˜ å°„
        self.known_models: Dict[str, str] = {
            # OpenAI æ¨¡å‹
            "gpt-4": "openai",
            "gpt-4-turbo": "openai",
            "gpt-4o": "openai",
            "gpt-3.5-turbo": "openai",
            "gpt-4o-mini": "openai",
            
            # Anthropic æ¨¡å‹
            "claude-opus-4-5-20251101": "anthropic",
           
            
            
            # DeepSeek æ¨¡å‹
            "deepseek-chat": "deepseek"
        }
        
        # æ¨¡å‹åˆ«åæ˜ å°„
        self.model_aliases: Dict[str, str] = {}
        
        # åˆå§‹åŒ–é»˜è®¤æ¨¡å‹é…ç½®
        self._initialize_default_models()
        
        # ä» JSON æ–‡ä»¶åŠ è½½è‡ªå®šä¹‰æ¨¡å‹
        self._load_from_json()
    
    def _initialize_default_models(self):
        """åˆå§‹åŒ–é»˜è®¤æ”¯æŒçš„æ¨¡å‹é…ç½®"""
        for model_name, provider in self.known_models.items():
            config = ModelConfig(
                model_name=model_name,
                provider=provider,
                api_base=self.provider_api_bases.get(provider),
                supports_vision="gpt-4" in model_name or "claude-3" in model_name
            )
            self.models[model_name] = config
    
    def _load_from_json(self):
        """ä» JSON æ–‡ä»¶åŠ è½½è‡ªå®šä¹‰æ¨¡å‹é…ç½®"""
        try:
            if self.model_file.exists():
                with open(self.model_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # åŠ è½½è‡ªå®šä¹‰æ¨¡å‹
                if 'custom_models' in data:
                    for model_data in data['custom_models']:
                        config = ModelConfig(
                            model_name=model_data['model_name'],
                            provider=model_data['provider'],
                            api_base=model_data.get('api_base'),
                            api_key=model_data.get('api_key'),
                            default_params=model_data.get('default_params', {}),
                            supports_streaming=model_data.get('supports_streaming', True),
                            supports_functions=model_data.get('supports_functions', False),
                            supports_vision=model_data.get('supports_vision', False),
                            max_tokens=model_data.get('max_tokens')
                        )
                        self.models[model_data['model_name']] = config
                
                # åŠ è½½åˆ«å
                if 'aliases' in data:
                    self.model_aliases = data['aliases']
                
                print(f"âœ… å·²ä» {self.model_file.name} åŠ è½½ {len(data.get('custom_models', []))} ä¸ªè‡ªå®šä¹‰æ¨¡å‹")
        except json.JSONDecodeError:
            print(f"âš ï¸  {self.model_file.name} æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡åŠ è½½")
        except Exception as e:
            print(f"âš ï¸  åŠ è½½æ¨¡å‹é…ç½®å¤±è´¥: {e}")
    
    def _save_to_json(self):
        """ä¿å­˜è‡ªå®šä¹‰æ¨¡å‹é…ç½®åˆ° JSON æ–‡ä»¶"""
        try:
            # åªä¿å­˜è‡ªå®šä¹‰æ¨¡å‹ï¼ˆä¸åœ¨ known_models ä¸­çš„ï¼‰
            custom_models = []
            for model_name, config in self.models.items():
                if model_name not in self.known_models:
                    model_data = {
                        'model_name': config.model_name,
                        'provider': config.provider,
                        'api_base': config.api_base,
                        'api_key': config.api_key,
                        'default_params': config.default_params,
                        'supports_streaming': config.supports_streaming,
                        'supports_functions': config.supports_functions,
                        'supports_vision': config.supports_vision,
                        'max_tokens': config.max_tokens
                    }
                    custom_models.append(model_data)
            
            data = {
                'custom_models': custom_models,
                'aliases': self.model_aliases
            }
            
            with open(self.model_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # print(f"âœ… å·²ä¿å­˜ {len(custom_models)} ä¸ªè‡ªå®šä¹‰æ¨¡å‹åˆ° {self.model_file.name}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ¨¡å‹é…ç½®å¤±è´¥: {e}")
    
    def register_model(
        self,
        model_name: str,
        provider: str,
        api_base: Optional[str] = None,
        api_key: Optional[str] = None,
        **kwargs
    ) -> ModelConfig:
        """
        æ³¨å†Œæ–°æ¨¡å‹ï¼ˆä¼šè‡ªåŠ¨ä¿å­˜åˆ° JSON æ–‡ä»¶ï¼‰
        
        Args:
            model_name: æ¨¡å‹åç§°
            provider: æä¾›å•†åç§°
            api_base: API åŸºç¡€ URL
            api_key: API å¯†é’¥
            **kwargs: å…¶ä»–é…ç½®å‚æ•°
            
        Returns:
            ModelConfig: æ¨¡å‹é…ç½®å¯¹è±¡
        """
        config = ModelConfig(
            model_name=model_name,
            provider=provider,
            api_base=api_base or self.provider_api_bases.get(provider),
            api_key=api_key,
            **kwargs
        )
        self.models[model_name] = config
        
        # ä¿å­˜åˆ° JSON æ–‡ä»¶
        self._save_to_json()
        
        print(f"âœ… å·²æ³¨å†Œæ¨¡å‹: {model_name} (æä¾›å•†: {provider})")
        return config
    
    def add_model_alias(self, alias: str, actual_model: str):
        """
        æ·»åŠ æ¨¡å‹åˆ«åï¼ˆä¼šè‡ªåŠ¨ä¿å­˜åˆ° JSON æ–‡ä»¶ï¼‰
        
        Args:
            alias: åˆ«å
            actual_model: å®é™…æ¨¡å‹åç§°
        """
        self.model_aliases[alias] = actual_model
        
        # ä¿å­˜åˆ° JSON æ–‡ä»¶
        self._save_to_json()
        
        print(f"âœ… å·²æ·»åŠ åˆ«å: {alias} -> {actual_model}")
    
    def get_llm_provider(
        self,
        model: str,
        api_base: Optional[str] = None,
        api_key: Optional[str] = None
    ) -> Tuple[str, str, Optional[str], Optional[str]]:
        """
        æ ¹æ®æ¨¡å‹åç§°è¯†åˆ«æä¾›å•†å’Œé…ç½®ï¼ˆæ¨¡ä»¿ LiteLLM çš„ get_llm_providerï¼‰
        
        Args:
            model: æ¨¡å‹åç§°
            api_base: å¯é€‰çš„ API base URL
            api_key: å¯é€‰çš„ API key
            
        Returns:
            Tuple[model_name, provider, api_key, api_base]
        """
        # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ«å
        if model in self.model_aliases:
            model = self.model_aliases[model]
        
        # 1. æ£€æŸ¥æ¨¡å‹åç§°ä¸­æ˜¯å¦åŒ…å«æä¾›å•†å‰ç¼€ (å¦‚ "groq/llama-3.1-8b")
        if "/" in model:
            parts = model.split("/", 1)
            if parts[0] in self.providers:
                provider = parts[0]
                model_name = parts[1]
                
                # è·å–è¯¥æä¾›å•†çš„é»˜è®¤é…ç½®
                final_api_base = api_base or self._get_api_base_from_env(provider) or self.provider_api_bases.get(provider)
                final_api_key = api_key or self._get_api_key_from_env(provider)
                
                return model_name, provider, final_api_key, final_api_base
        
        # 2. æ£€æŸ¥æ˜¯å¦æ˜¯å·²æ³¨å†Œçš„æ¨¡å‹
        if model in self.models:
            config = self.models[model]
            final_api_base = api_base or self._get_api_base_from_env(config.provider) or config.api_base
            final_api_key = api_key or config.api_key or self._get_api_key_from_env(config.provider)
            
            return config.model_name, config.provider, final_api_key, final_api_base
        
        # 3. æ£€æŸ¥æ˜¯å¦åœ¨å·²çŸ¥æ¨¡å‹åˆ—è¡¨ä¸­
        if model in self.known_models:
            provider = self.known_models[model]
            final_api_base = api_base or self._get_api_base_from_env(provider) or self.provider_api_bases.get(provider)
            final_api_key = api_key or self._get_api_key_from_env(provider)
            
            return model, provider, final_api_key, final_api_base
        
        # 4. å¦‚æœæä¾›äº† api_baseï¼Œå°è¯•ä»ä¸­è¯†åˆ«æä¾›å•†
        if api_base:
            for provider, base_url in self.provider_api_bases.items():
                if base_url in api_base:
                    final_api_key = api_key or self._get_api_key_from_env(provider)
                    return model, provider, final_api_key, api_base
        
        # 5. æ— æ³•è¯†åˆ«ï¼ŒæŠ›å‡ºé”™è¯¯
        raise ValueError(
            f"âŒ æ— æ³•è¯†åˆ«æ¨¡å‹: {model}\n"
            f"æ”¯æŒçš„æ ¼å¼:\n"
            f"  1. ä½¿ç”¨æä¾›å•†å‰ç¼€: 'groq/llama-3.1-8b'\n"
            f"  2. å·²çŸ¥æ¨¡å‹åç§°: {list(self.known_models.keys())[:5]}...\n"
            f"  3. æ³¨å†Œæ–°æ¨¡å‹: manager.register_model(...)"
        )
    
    def _get_api_key_from_env(self, provider: str) -> Optional[str]:
        """ä»ç¯å¢ƒå˜é‡è·å– API å¯†é’¥ï¼ˆä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€çš„ API_KEYï¼‰"""
        # ä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€çš„ API_KEY
        unified_key = os.environ.get("API_KEY")
        if unified_key:
            return unified_key
        
        # å¦‚æœæ²¡æœ‰ç»Ÿä¸€çš„ API_KEYï¼Œåˆ™ä½¿ç”¨ç‰¹å®šæä¾›å•†çš„ key
        env_keys = {
            "openai": "OPENAI_API_KEY",
            "anthropic": "ANTHROPIC_API_KEY",
            "groq": "GROQ_API_KEY",
            "mistral": "MISTRAL_API_KEY",
            "deepseek": "DEEPSEEK_API_KEY",
            "together_ai": "TOGETHER_API_KEY",
            "perplexity": "PERPLEXITY_API_KEY",
            "anyscale": "ANYSCALE_API_KEY",
        }
        
        env_var = env_keys.get(provider)
        if env_var:
            return os.environ.get(env_var)
        return None
    
    def _get_api_base_from_env(self, provider: str) -> Optional[str]:
        """ä»ç¯å¢ƒå˜é‡è·å– API Base URLï¼ˆä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€çš„ BASE_URLï¼‰"""
        # ä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€çš„ BASE_URL
        unified_base = os.environ.get("BASE_URL")
        if unified_base:
            return unified_base
        
        # å¦‚æœæ²¡æœ‰ç»Ÿä¸€çš„ BASE_URLï¼Œåˆ™ä½¿ç”¨ç‰¹å®šæä¾›å•†çš„ base URL
        env_var = f"{provider.upper()}_API_BASE"
        return os.environ.get(env_var)
    
    def get_model_config(self, model: str) -> Optional[ModelConfig]:
        """è·å–æ¨¡å‹é…ç½®"""
        if model in self.model_aliases:
            model = self.model_aliases[model]
        return self.models.get(model)
    
    def list_models(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„æ¨¡å‹"""
        return list(self.models.keys())
    
    def list_providers(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„æä¾›å•†"""
        return self.providers
    
    def remove_model(self, model: str):
        """ç§»é™¤å·²æ³¨å†Œçš„æ¨¡å‹ï¼ˆä¼šè‡ªåŠ¨ä¿å­˜åˆ° JSON æ–‡ä»¶ï¼‰"""
        if model in self.models:
            # ä¸èƒ½åˆ é™¤é¢„å®šä¹‰æ¨¡å‹
            if model in self.known_models:
                print(f"âš ï¸  ä¸èƒ½åˆ é™¤é¢„å®šä¹‰æ¨¡å‹: {model}")
                return
            
            del self.models[model]
            
            # ä¿å­˜åˆ° JSON æ–‡ä»¶
            self._save_to_json()
            
            print(f"âœ… å·²ç§»é™¤æ¨¡å‹: {model}")
        else:
            print(f"âš ï¸  æ¨¡å‹ä¸å­˜åœ¨: {model}")
    
    def update_model(self, model: str, **kwargs):
        """æ›´æ–°æ¨¡å‹é…ç½®ï¼ˆä¼šè‡ªåŠ¨ä¿å­˜åˆ° JSON æ–‡ä»¶ï¼‰"""
        if model not in self.models:
            raise ValueError(f"æ¨¡å‹ {model} ä¸å­˜åœ¨")
        
        config = self.models[model]
        for key, value in kwargs.items():
            if hasattr(config, key):
                setattr(config, key, value)
        
        # ä¿å­˜åˆ° JSON æ–‡ä»¶
        self._save_to_json()
        
        print(f"âœ… å·²æ›´æ–°æ¨¡å‹é…ç½®: {model}")
        return config
    
    def get_model_info(self, model: str) -> Dict:
        """è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯"""
        try:
            model_name, provider, api_key, api_base = self.get_llm_provider(model)
            
            config = self.get_model_config(model)
            
            info = {
                "model_name": model_name,
                "provider": provider,
                "api_base": api_base,
                "has_api_key": api_key is not None,
            }
            
            if config:
                info.update({
                    "supports_streaming": config.supports_streaming,
                    "supports_functions": config.supports_functions,
                    "supports_vision": config.supports_vision,
                    "max_tokens": config.max_tokens,
                })
            
            return info
        except Exception as e:
            return {"error": str(e)}
    
    def print_model_info(self, model: str):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        info = self.get_model_info(model)
        print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯: {model}")
        print("=" * 50)
        for key, value in info.items():
            print(f"  {key}: {value}")
        print("=" * 50)


# å…¨å±€æ¨¡å‹ç®¡ç†å™¨å®ä¾‹
model_manager = ModelManager()


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    print("ğŸš€ æ¨¡å‹ç®¡ç†å™¨ç¤ºä¾‹\n")
    
    # 1. ä½¿ç”¨å·²çŸ¥æ¨¡å‹
    print("1ï¸âƒ£ è¯†åˆ«å·²çŸ¥æ¨¡å‹:")
    model, provider, key, base = model_manager.get_llm_provider("gpt-4")
    print(f"   æ¨¡å‹: {model}, æä¾›å•†: {provider}, API Base: {base}\n")
    
    # 2. ä½¿ç”¨æä¾›å•†å‰ç¼€
    print("2ï¸âƒ£ ä½¿ç”¨æä¾›å•†å‰ç¼€:")
    model, provider, key, base = model_manager.get_llm_provider("groq/llama-3.1-8b")
    print(f"   æ¨¡å‹: {model}, æä¾›å•†: {provider}, API Base: {base}\n")
    
    # 3. æ³¨å†Œè‡ªå®šä¹‰æ¨¡å‹
    print("3ï¸âƒ£ æ³¨å†Œè‡ªå®šä¹‰æ¨¡å‹:")
    model_manager.register_model(
        model_name="my-custom-model",
        provider="openai",
        api_base="https://my-custom-endpoint.com/v1",
        supports_vision=True
    )
    
    # 4. æ·»åŠ åˆ«å
    print("\n4ï¸âƒ£ æ·»åŠ æ¨¡å‹åˆ«å:")
    model_manager.add_model_alias("gpt4", "gpt-4")
    model, provider, key, base = model_manager.get_llm_provider("gpt4")
    print(f"   åˆ«å 'gpt4' -> å®é™…æ¨¡å‹: {model}\n")
    
    # 5. æŸ¥çœ‹æ¨¡å‹è¯¦ç»†ä¿¡æ¯
    print("5ï¸âƒ£ æŸ¥çœ‹æ¨¡å‹è¯¦ç»†ä¿¡æ¯:")
    model_manager.print_model_info("gpt-4")
    
    # 6. åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
    print(f"\n6ï¸âƒ£ å·²æ³¨å†Œæ¨¡å‹æ•°é‡: {len(model_manager.list_models())}")
    print(f"   æ”¯æŒçš„æä¾›å•†: {', '.join(model_manager.list_providers()[:5])}...")

