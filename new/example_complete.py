"""
å®Œæ•´ç¤ºä¾‹ï¼šå¦‚ä½•ä½¿ç”¨ model_manager å’Œ message_manager
"""

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from model_manager import completion
from message_manager import MessageManager
import json


def example_1_direct_use():
    """ç¤ºä¾‹ 1: ç›´æ¥ä½¿ç”¨ï¼ˆæ¨èï¼‰- ä¸éœ€è¦æ‰‹åŠ¨ä½¿ç”¨ MessageManager"""
    print("=" * 60)
    print("ç¤ºä¾‹ 1: ç›´æ¥ä½¿ç”¨ completion()")
    print("=" * 60)
    
    try:
        # 1. åˆ›å»º LangChain Message å¯¹è±¡
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹"),
            HumanMessage(content="ç”¨ä¸€å¥è¯ä»‹ç» Python")
        ]
        
        # 2. ç›´æ¥è°ƒç”¨ï¼ˆMessageManager åœ¨å†…éƒ¨è‡ªåŠ¨ä½¿ç”¨ï¼‰
        print("\nğŸ“¤ è°ƒç”¨æ¨¡å‹...")
        resp = completion(model="openai/gpt-4o", messages=messages)
        
        # 3. ä½¿ç”¨åŸå§‹ JSON å“åº”
        print(f"\nâœ… å“åº”ç±»å‹: {type(resp).__name__}")  # dict
        print(f"ğŸ’¬ å†…å®¹: {resp['choices'][0]['message']['content']}")
        print(f"ğŸ“Š Token ä½¿ç”¨: {resp['usage']}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


def example_2_view_conversion():
    """ç¤ºä¾‹ 2: æŸ¥çœ‹ MessageManager çš„æ ¼å¼è½¬æ¢ï¼ˆè°ƒè¯•ç”¨ï¼‰"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 2: æŸ¥çœ‹ MessageManager æ ¼å¼è½¬æ¢")
    print("=" * 60)
    
    # åˆ›å»ºæ¶ˆæ¯
    messages = [
        HumanMessage(content="ä½ å¥½"),
        AIMessage(content="ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„ï¼Ÿ"),
        HumanMessage(content="ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
    ]
    
    # æ–¹å¼ 1: è½¬æ¢ä¸º chat/completions æ ¼å¼
    print("\n1ï¸âƒ£ Chat/Completions æ ¼å¼ï¼ˆæ ‡å‡†ï¼‰:")
    msg_manager_chat = MessageManager(api_type="chat/completions")
    api_format_chat = msg_manager_chat(messages)
    print(json.dumps(api_format_chat, indent=2, ensure_ascii=False))
    
    # æ–¹å¼ 2: è½¬æ¢ä¸º responses æ ¼å¼
    print("\n2ï¸âƒ£ Responses æ ¼å¼ï¼ˆGPT-5ï¼‰:")
    msg_manager_resp = MessageManager(api_type="responses")
    api_format_resp = msg_manager_resp(messages)
    print(json.dumps(api_format_resp, indent=2, ensure_ascii=False))
    
    print("\nğŸ’¡ æ³¨æ„: è°ƒç”¨ completion() æ—¶ï¼ŒMessageManager ä¼šè‡ªåŠ¨é€‰æ‹©æ­£ç¡®çš„æ ¼å¼")


def example_3_multi_turn_conversation():
    """ç¤ºä¾‹ 3: å¤šè½®å¯¹è¯å®Œæ•´æµç¨‹"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 3: å¤šè½®å¯¹è¯")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–å¯¹è¯å†å²
        conversation = [
            SystemMessage(content="ä½ æ˜¯ Python ç¼–ç¨‹åŠ©æ‰‹")
        ]
        
        # ç¬¬ä¸€è½®å¯¹è¯
        print("\nğŸ‘¤ ç”¨æˆ·: ä»€ä¹ˆæ˜¯åˆ—è¡¨æ¨å¯¼å¼ï¼Ÿ")
        conversation.append(HumanMessage(content="ä»€ä¹ˆæ˜¯åˆ—è¡¨æ¨å¯¼å¼ï¼Ÿ"))
        
        resp1 = completion(model="openai/gpt-4o", messages=conversation)
        assistant_reply1 = resp1['choices'][0]['message']['content']
        print(f"ğŸ¤– åŠ©æ‰‹: {assistant_reply1[:100]}...")
        
        # å°†åŠ©æ‰‹å›å¤æ·»åŠ åˆ°å†å²
        conversation.append(AIMessage(content=assistant_reply1))
        
        # ç¬¬äºŒè½®å¯¹è¯
        print("\nğŸ‘¤ ç”¨æˆ·: ç»™æˆ‘ä¸€ä¸ªä¾‹å­")
        conversation.append(HumanMessage(content="ç»™æˆ‘ä¸€ä¸ªä¾‹å­"))
        
        resp2 = completion(model="openai/gpt-4o", messages=conversation)
        assistant_reply2 = resp2['choices'][0]['message']['content']
        print(f"ğŸ¤– åŠ©æ‰‹: {assistant_reply2[:100]}...")
        
        # ç»Ÿè®¡
        print(f"\nğŸ“Š å¯¹è¯ç»Ÿè®¡:")
        print(f"  æ¶ˆæ¯æ•°é‡: {len(conversation) + 1}")  # +1 for latest response
        print(f"  ç¬¬ä¸€è½® Token: {resp1['usage']['total_tokens']}")
        print(f"  ç¬¬äºŒè½® Token: {resp2['usage']['total_tokens']}")
        print(f"  æ€»è®¡ Token: {resp1['usage']['total_tokens'] + resp2['usage']['total_tokens']}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def example_4_with_vision():
    """ç¤ºä¾‹ 4: è§†è§‰æ¨¡å‹ï¼ˆå¸¦å›¾ç‰‡ï¼‰"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 4: è§†è§‰æ¨¡å‹æ¶ˆæ¯æ ¼å¼")
    print("=" * 60)
    
    # åˆ›å»ºåŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯
    messages = [
        HumanMessage(content=[
            {"type": "text", "text": "è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"},
            {
                "type": "image_url",
                "image_url": {"url": "https://example.com/image.jpg"}
            }
        ])
    ]
    
    # æŸ¥çœ‹è½¬æ¢åçš„æ ¼å¼
    msg_manager = MessageManager(api_type="chat/completions")
    api_format = msg_manager(messages)
    
    print("\nğŸ“‹ åŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯æ ¼å¼:")
    print(json.dumps(api_format, indent=2, ensure_ascii=False))
    
    print("\nğŸ’¡ ä½¿ç”¨æ–¹å¼:")
    print("resp = completion(model='openai/gpt-4o', messages=messages)")
    print("# å†…éƒ¨ä¼šè‡ªåŠ¨è½¬æ¢å¹¶å‘é€")


def example_5_comparison():
    """ç¤ºä¾‹ 5: å¯¹æ¯”ä¸¤ç§ API æ ¼å¼"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 5: Chat/Completions vs Responses API")
    print("=" * 60)
    
    messages = [HumanMessage(content="Hello!")]
    
    # Chat/Completions æ ¼å¼
    msg_manager_chat = MessageManager(api_type="chat/completions")
    chat_format = msg_manager_chat(messages)
    
    # Responses æ ¼å¼
    msg_manager_resp = MessageManager(api_type="responses")
    resp_format = msg_manager_resp(messages)
    
    print("\nğŸ“‹ Chat/Completions æ ¼å¼ï¼ˆGPT-4, Claude, Geminiï¼‰:")
    print(json.dumps(chat_format, indent=2))
    
    print("\nğŸ“‹ Responses æ ¼å¼ï¼ˆGPT-5ï¼‰:")
    print(json.dumps(resp_format, indent=2))
    
    print("\nğŸ”‘ å…³é”®åŒºåˆ«:")
    print("  â€¢ Chat/Completions: 'type': 'text'")
    print("  â€¢ Responses:        'type': 'input_text'")


def main():
    """è¿è¡Œç¤ºä¾‹"""
    print("\n" + "ğŸ¯" * 30)
    print("MessageManager + ModelManager å®Œæ•´ä½¿ç”¨æŒ‡å—")
    print("ğŸ¯" * 30)
    
    print("\nğŸ“– æ ¸å¿ƒæ¦‚å¿µ:")
    print("  â€¢ MessageManager: æ¶ˆæ¯æ ¼å¼è½¬æ¢å·¥å…·")
    print("  â€¢ ModelManager:   æ¨¡å‹è°ƒç”¨å’Œç®¡ç†")
    print("  â€¢ completion():   ç»Ÿä¸€è°ƒç”¨æ¥å£\n")
    
    # å±•ç¤ºæ ¼å¼ï¼ˆä¸éœ€è¦ API Keyï¼‰
    example_2_view_conversion()
    example_4_with_vision()
    example_5_comparison()
    
    # å®é™…è°ƒç”¨ï¼ˆéœ€è¦ API Keyï¼‰
    print("\n" + "=" * 60)
    user_input = input("æ˜¯å¦è¿è¡Œå®é™… API è°ƒç”¨ç¤ºä¾‹ï¼Ÿ(éœ€è¦ API Key) (y/n): ")
    if user_input.lower() == 'y':
        example_1_direct_use()
        example_3_multi_turn_conversation()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ç¤ºä¾‹å®Œæˆ!")
    print("=" * 60)
    
    print("\nğŸ“š ä½¿ç”¨æ€»ç»“:")
    print("""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. åˆ›å»º LangChain Message å¯¹è±¡                      â”‚
    â”‚    messages = [HumanMessage(content="Hello")]      â”‚
    â”‚                                                     â”‚
    â”‚ 2. è°ƒç”¨ completion()                                â”‚
    â”‚    resp = completion(model="openai/gpt-4o",        â”‚
    â”‚                      messages=messages)            â”‚
    â”‚                                                     â”‚
    â”‚ 3. MessageManager è‡ªåŠ¨åœ¨å†…éƒ¨ä½¿ç”¨ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒç”¨      â”‚
    â”‚                                                     â”‚
    â”‚ 4. è·å–åŸå§‹ JSON å“åº”                               â”‚
    â”‚    content = resp['choices'][0]['message']['content']â”‚
    â”‚    usage = resp['usage']                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ğŸ’¡ é€šå¸¸æƒ…å†µä¸‹ï¼Œä½ åªéœ€è¦ï¼š
       1. å¯¼å…¥: from model_manager import completion
       2. è°ƒç”¨: resp = completion(model, messages)
       3. ä½¿ç”¨: resp['choices'][0]['message']['content']
       
    ğŸ”§ MessageManager åªåœ¨ä»¥ä¸‹æƒ…å†µæ‰‹åŠ¨ä½¿ç”¨ï¼š
       â€¢ è°ƒè¯•æ¶ˆæ¯æ ¼å¼
       â€¢ æŸ¥çœ‹ API è¯·æ±‚ç»“æ„
       â€¢ ç†è§£æ ¼å¼è½¬æ¢è¿‡ç¨‹
    """)


if __name__ == "__main__":
    main()

