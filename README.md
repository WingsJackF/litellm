# LiteLLM ç®€åŒ–ç‰ˆæ¨¡å‹ç®¡ç†å™¨

ä¸€ä¸ªè½»é‡çº§çš„ LLM æ¨¡å‹ç®¡ç†å·¥å…·ï¼Œ**é›¶ä¾èµ– LangChain**ï¼ŒåŸºäº OpenAI SDKï¼Œæ”¯æŒå¤šç§æ¨¡å‹æä¾›å•†å’Œç»Ÿä¸€çš„è°ƒç”¨æ¥å£ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ¯ **æ™ºèƒ½ API é€‰æ‹©**: æ ¹æ®è°ƒç”¨å‡½æ•°è‡ªåŠ¨é€‰æ‹©æ­£ç¡®çš„ API ç«¯ç‚¹
- ğŸ”Œ **å¤šæä¾›å•†æ”¯æŒ**: OpenAI, Anthropic, Google, DeepSeek ç­‰ï¼ˆOpenAI å…¼å®¹ APIï¼‰
- ğŸ“¦ **åŸå§‹ JSON å“åº”**: ç›´æ¥è¿”å›å®Œæ•´çš„ API å“åº”æ•°æ®
- ğŸ’¾ **æ¨¡å‹ç®¡ç†**: è‡ªåŠ¨åŠ è½½å’ŒæŒä¹…åŒ–æ¨¡å‹é…ç½®
- ğŸ”„ **æµå¼è¾“å‡º**: å®Œæ•´æ”¯æŒæµå¼å“åº”
- ğŸ› ï¸ **å·¥å…·è°ƒç”¨**: æ”¯æŒ Function Calling
- ğŸ“Š **è¯¦ç»†ç»Ÿè®¡**: å®Œæ•´çš„ token ä½¿ç”¨å’Œå…ƒæ•°æ®
- ğŸª¶ **è½»é‡çº§**: åŸºäº OpenAI å®˜æ–¹ SDKï¼Œç¨³å®šå¯é 

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install openai python-dotenv
# æˆ–è€…
pip install -r requirements.txt
```

### é…ç½®ç¯å¢ƒ

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# ç»Ÿä¸€ API Keyï¼ˆæ¨èï¼‰
API_KEY=your-api-key-here
BASE_URL=https://api.openai.com/v1
```

### åŸºç¡€ä½¿ç”¨

```python
from message_manager import HumanMessage
from model_manager import completion

# è°ƒç”¨æ¨¡å‹
messages = [HumanMessage(content="Hello!")]
response = completion(model="openai/gpt-4o", messages=messages)

# è·å–ç»“æœ
print(response['choices'][0]['message']['content'])
print(response['usage'])
```

## ğŸ“– ä¸¤ç§ API è°ƒç”¨æ–¹å¼

### completion() - æ ‡å‡† APIï¼ˆæ¨èï¼‰

ç”¨äºå¤§å¤šæ•°æ¨¡å‹ï¼Œ**è‡ªåŠ¨ä½¿ç”¨ `chat/completions` ç«¯ç‚¹**ï¼š

```python
from model_manager import completion

# è‡ªåŠ¨ä½¿ç”¨ chat/completions API
response = completion(
    model="openai/gpt-4o",
    messages=messages
)

# è¿”å›åŸå§‹ JSON
# {
#   "id": "chatcmpl-xxx",
#   "model": "gpt-4o",
#   "choices": [...],
#   "usage": {...}
# }
```

**æ”¯æŒçš„æ¨¡å‹ï¼š**
- OpenAI: gpt-4o, gpt-4-turbo
- Anthropic: claude-3-5-sonnet-20241022
- Google: gemini-1.5-pro
- DeepSeek: deepseek-chat
- å…¶ä»–å…¼å®¹ OpenAI API çš„æ¨¡å‹

### response() - æ–°ç‰ˆ API

ç”¨äºæ”¯æŒ responses API çš„æ¨¡å‹ï¼Œ**è‡ªåŠ¨ä½¿ç”¨ `responses` ç«¯ç‚¹**ï¼š

```python
from model_manager import response

# è‡ªåŠ¨ä½¿ç”¨ responses API
resp = response(
    model="openai/gpt-5",
    messages=messages
)
```

## ğŸ¯ æ™ºèƒ½ API é€‰æ‹©

### å…³é”®æ”¹è¿›

**ä¸å†éœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® `use_responses_api`ï¼**

è°ƒç”¨å‡½æ•°è‡ªåŠ¨å†³å®šä½¿ç”¨å“ªä¸ª APIï¼š

```python
# âœ… è‡ªåŠ¨ä½¿ç”¨ chat/completions
completion(model="openai/gpt-4o", messages=messages)
#   â†’ POST /chat/completions

# âœ… è‡ªåŠ¨ä½¿ç”¨ responses
response(model="openai/gpt-5", messages=messages)
#   â†’ POST /responses
```

### å·¥ä½œåŸç†

```python
# completion() å†…éƒ¨è‡ªåŠ¨è®¾ç½®
model_manager.chat(..., use_responses_api=False)

# response() å†…éƒ¨è‡ªåŠ¨è®¾ç½®
model_manager.chat(..., use_responses_api=True)
```

## ğŸ’¬ æ¶ˆæ¯æ ¼å¼

ä½¿ç”¨å†…ç½®çš„ Message ç±»ï¼ˆæ— éœ€ LangChainï¼‰ï¼š

```python
from message_manager import HumanMessage, AIMessage, SystemMessage

messages = [
    SystemMessage(content="ä½ æ˜¯åŠ©æ‰‹"),
    HumanMessage(content="ä½ å¥½"),
    AIMessage(content="ä½ å¥½ï¼"),
    HumanMessage(content="ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
]

resp = completion(model="openai/gpt-4o", messages=messages)
```

## ğŸ“Š å“åº”æ ¼å¼

è¿”å›å®Œæ•´çš„ OpenAI API JSON æ ¼å¼ï¼š

```json
{
  "id": "chatcmpl-xxx",
  "created": 1751494488,
  "model": "gpt-4o",
  "object": "chat.completion",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "content": "Hello! How can I help you?",
        "role": "assistant",
        "tool_calls": null
      }
    }
  ],
  "usage": {
    "prompt_tokens": 13,
    "completion_tokens": 39,
    "total_tokens": 52,
    "prompt_tokens_details": {
      "cached_tokens": 0
    }
  }
}
```

### æå–ä¿¡æ¯

```python
# è·å–å†…å®¹
content = resp['choices'][0]['message']['content']

# è·å– Token ç»Ÿè®¡
usage = resp['usage']
print(f"è¾“å…¥: {usage['prompt_tokens']}")
print(f"è¾“å‡º: {usage['completion_tokens']}")
print(f"æ€»è®¡: {usage['total_tokens']}")

# è·å–å…ƒæ•°æ®
model_used = resp['model']
response_id = resp['id']
created_at = resp['created']
```

## ğŸ”§ æ¨¡å‹åç§°æ ¼å¼

æ”¯æŒä¸‰ç§æ ¼å¼ï¼š

```python
# 1. provider/modelï¼ˆæ¨èï¼Œæ›´æ¸…æ™°ï¼‰
completion(model="openai/gpt-4o", messages=messages)
completion(model="anthropic/claude-3-5-sonnet-20241022", messages=messages)

# 2. ä»…æ¨¡å‹å
completion(model="gpt-4o", messages=messages)

# 3. ä½¿ç”¨åˆ«åï¼ˆå¦‚æœåœ¨ model.json ä¸­é…ç½®ï¼‰
completion(model="gemini", messages=messages)  # â†’ gemini-pro
```

## ğŸ› ï¸ é«˜çº§åŠŸèƒ½

### 1. Response Format - JSON è¾“å‡º

å¼ºåˆ¶æ¨¡å‹ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š

```python
from message_manager import SystemMessage, HumanMessage

messages = [
    SystemMessage(content="ä½ æ˜¯åŠ©æ‰‹ï¼Œè¯·ä»¥ JSON æ ¼å¼å›å¤"),
    HumanMessage(content="ä»‹ç» Pythonï¼ŒåŒ…å«ï¼šname, year, features")
]

resp = completion(
    model="openai/gpt-4o",
    messages=messages,
    response_format={"type": "json_object"}
)

# è§£æ JSON
import json
content = resp['choices'][0]['message']['content']
data = json.loads(content)
print(data)
# è¾“å‡º: {"name": "Python", "year": 1991, "features": [...]}
```

### 2. Tool Call - å·¥å…·è°ƒç”¨

è®©æ¨¡å‹è°ƒç”¨å¤–éƒ¨å·¥å…·ï¼š

```python
from message_manager import HumanMessage

tools = [{
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "è·å–åŸå¸‚å¤©æ°”",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {"type": "string", "description": "åŸå¸‚åç§°"}
            },
            "required": ["city"]
        }
    }
}]

resp = completion(
    model="openai/gpt-4o",
    messages=[HumanMessage(content="åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ")],
    tools=tools
)

# æ£€æŸ¥å·¥å…·è°ƒç”¨
import json
message = resp['choices'][0]['message']
if message.get('tool_calls'):
    for tool_call in message['tool_calls']:
        func_name = tool_call['function']['name']
        func_args = json.loads(tool_call['function']['arguments'])
        print(f"è°ƒç”¨: {func_name}({func_args})")
        # è¾“å‡º: è°ƒç”¨: get_weather({'city': 'åŒ—äº¬'})
```

### 3. è§†è§‰æ¨¡å‹ - å›¾ç‰‡ç†è§£

å¤„ç†åŒ…å«å›¾ç‰‡çš„è¾“å…¥ï¼š

```python
from message_manager import HumanMessage

messages = [
    HumanMessage(content=[
        {"type": "text", "text": "è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"},
        {
            "type": "image_url",
            "image_url": {"url": "https://example.com/image.jpg"}
        }
    ])
]

resp = completion(model="openai/gpt-4o", messages=messages)
content = resp['choices'][0]['message']['content']
print(content)
```

### 4. å¤šå·¥å…·é€‰æ‹©

æ¨¡å‹å¯ä»¥æ ¹æ®é—®é¢˜é€‰æ‹©è°ƒç”¨å¤šä¸ªå·¥å…·ï¼š

```python
from message_manager import HumanMessage

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–å¤©æ°”",
            "parameters": {"type": "object", "properties": {"city": {"type": "string"}}}
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_time",
            "description": "è·å–æ—¶é—´",
            "parameters": {"type": "object", "properties": {"city": {"type": "string"}}}
        }
    }
]

resp = completion(
    model="openai/gpt-4o",
    messages=[HumanMessage(content="å‘Šè¯‰æˆ‘åŒ—äº¬çš„å¤©æ°”å’Œæ—¶é—´")],
    tools=tools
)

# æ¨¡å‹å¯èƒ½ä¼šè°ƒç”¨å¤šä¸ªå·¥å…·
tool_calls = resp['choices'][0]['message'].get('tool_calls', [])
print(f"è°ƒç”¨äº† {len(tool_calls)} ä¸ªå·¥å…·")
```

## ğŸ“‹ æ¨¡å‹é…ç½®

é…ç½®ä¿å­˜åœ¨ `model.json` æ–‡ä»¶ä¸­ï¼š

```json
{
  "custom_models": [
    {
      "model_name": "my-model",
      "provider": "openai",
      "api_base": "https://api.example.com/v1",
      "max_tokens": 4096
    }
  ],
  "aliases": {
    "gemini": "gemini-pro"
  }
}
```

**æ³¨æ„**: ä¸å†éœ€è¦è®¾ç½® `use_responses_api` å­—æ®µï¼

## ğŸ“š ç¤ºä¾‹å’Œæµ‹è¯•æ–‡ä»¶

### ç¤ºä¾‹æ–‡ä»¶

- **example_api_calls.py** - API è°ƒç”¨ç¤ºä¾‹ï¼ˆå«èœå•é€‰æ‹©ï¼‰
- **test_features.py** - åŠŸèƒ½æµ‹è¯•ï¼ˆResponse Format + Tool Callï¼‰

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œäº¤äº’å¼ç¤ºä¾‹ï¼ˆå¯é€‰æ‹©æµ‹è¯•é¡¹ï¼‰
python example_api_calls.py

# è¿è¡ŒåŠŸèƒ½æµ‹è¯•ï¼ˆè‡ªåŠ¨è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼‰
python test_features.py
```

### æµ‹è¯•å†…å®¹

**test_features.py** åŒ…å«ï¼š
1. âœ… Response Format - JSON è¾“å‡ºæµ‹è¯•
2. âœ… Tool Call - å•ä¸ªå·¥å…·è°ƒç”¨
3. âœ… Tool Call - å¤šä¸ªå·¥å…·é€‰æ‹©
4. âœ… ç»„åˆåŠŸèƒ½æµ‹è¯•

## ğŸ”„ API å¯¹æ¯”

| ç‰¹æ€§ | completion() | response() |
|------|-------------|-----------|
| **ç”¨é€”** | å¤§å¤šæ•°æ¨¡å‹ | GPT-5 ç­‰æ–°æ¨¡å‹ |
| **API ç«¯ç‚¹** | `/chat/completions` | `/responses` |
| **è‡ªåŠ¨è®¾ç½®** | âœ… use_responses_api=False | âœ… use_responses_api=True |
| **æ¨èåº¦** | â­â­â­â­â­ | â­â­â­ |

## ğŸ’¡ ä½¿ç”¨å»ºè®®

1. **é»˜è®¤ä½¿ç”¨ `completion()`**ï¼šé€‚ç”¨äº 99% çš„åœºæ™¯
2. **ä»…åœ¨éœ€è¦æ—¶ä½¿ç”¨ `response()`**ï¼šå¦‚ GPT-5 ç­‰æ˜ç¡®ä½¿ç”¨ responses API çš„æ¨¡å‹
3. **ä½¿ç”¨ `provider/model` æ ¼å¼**ï¼šæ›´æ¸…æ™°æ˜“è¯»
4. **é…ç½®ç¯å¢ƒå˜é‡**ï¼šä½¿ç”¨ `.env` æ–‡ä»¶ç®¡ç†æ•æ„Ÿä¿¡æ¯

## ğŸ› å¸¸è§é—®é¢˜

**Q: å¦‚ä½•é€‰æ‹© completion è¿˜æ˜¯ responseï¼Ÿ**  
A: æ ¹æ®æ¨¡å‹çš„ API ç«¯ç‚¹ï¼š
- GPT-4, Claude, Gemini â†’ `completion()`
- GPT-5 â†’ `response()`

**Q: è¿˜éœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® use_responses_api å—ï¼Ÿ**  
A: **ä¸éœ€è¦ï¼** ç°åœ¨è°ƒç”¨å‡½æ•°ä¼šè‡ªåŠ¨è®¾ç½®ã€‚

**Q: æ¨¡å‹åç§°å¿…é¡»å¸¦ provider å‰ç¼€å—ï¼Ÿ**  
A: ä¸æ˜¯å¿…é¡»çš„ï¼Œä½†æ¨èä½¿ç”¨ `provider/model` æ ¼å¼ã€‚

**Q: å¦‚ä½•æŸ¥çœ‹å®Œæ•´çš„ API è¯·æ±‚ï¼Ÿ**  
A: å“åº”ä¸­åŒ…å«äº†æ‰€æœ‰ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½¿ç”¨çš„æ¨¡å‹ã€token ç»Ÿè®¡ç­‰ã€‚

## ğŸ‰ æ ¸å¿ƒä¼˜åŠ¿

### ä¹‹å‰

```python
# éœ€è¦åœ¨ model.json ä¸­é…ç½®
{
  "model_name": "gpt-5",
  "use_responses_api": true  # å¿…é¡»æ‰‹åŠ¨è®¾ç½®
}

# è°ƒç”¨æ—¶è¿˜è¦è®°ä½é…ç½®
completion(model="gpt-5", messages=messages)  # å¯èƒ½å‡ºé”™
```

### ç°åœ¨

```python
# ä¸éœ€è¦é…ç½®ï¼Œç›´æ¥è°ƒç”¨æ­£ç¡®çš„å‡½æ•°
response(model="openai/gpt-5", messages=messages)  # âœ… è‡ªåŠ¨ä½¿ç”¨æ­£ç¡® API

completion(model="openai/gpt-4o", messages=messages)  # âœ… è‡ªåŠ¨ä½¿ç”¨æ­£ç¡® API
```

## ğŸ“ è·å–å¸®åŠ©

- æŸ¥çœ‹ç¤ºä¾‹ï¼š`example_complete.py`
- æŸ¥çœ‹é…ç½®ï¼š`model.json`

---

**Happy Coding! ğŸ‰**
